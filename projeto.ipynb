{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconhecimento de dígitos do painel de senha do restaurante do Insper\n",
    "\n",
    "## Descrição do projeto e problema a ser estudado\n",
    "\n",
    "O objetivo deste projeto é desenvolver uma solução para permitir que os clientes do restaurante do 6° andar do prédio 2 da faculdade Insper possam acompanhar a senha atual sem precisar estar próximo do painel. Notamos no nosso dia a dia que muitos alunos não conseguem ouvir ou ver a senha atual, já que a maior parte dos assentos fica longe do painel.\n",
    "\n",
    "Para resolver esse problema, utilizaremos técnicas de reconhecimento de dígitos por meio de imagens. Inicialmente, faremos o reconhecimento de dígitos do painel de senha com o uso de OpenCV e OCR em um Jupyter Notebook. Com isso, conseguiremos extrair as informações necessárias e armazená-las em um banco de dados. Posteriormente, poderemos criar um aplicativo que exibe a senha atual, permitindo que os clientes possam acompanhar o seu pedido sem precisar estar próximo do painel.\n",
    "\n",
    "## Origem dos dados\n",
    "\n",
    "Os dados serão gerados por meio de um vídeo feito por nós do painel de senha do restaurante do Insper. Utilizaremos esse vídeo para treinar o modelo de reconhecimento de dígitos.\n",
    "\n",
    "## Técnicas para extrair e tratar os dados\n",
    "\n",
    "Os dados serão extraídos a partir de um vídeo que captura o painel de senha do restaurante do Insper em funcionamento. Faremos o tratamento das imagens por meio de técnicas de OpenCV e OCR para extrair os dígitos do painel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tutuc\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\models\\detection\\anchor_utils.py:63: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(\"cpu\"),\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import easyocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit_recognition(img):\n",
    "    # Carrega a imagem\n",
    "    # img = cv2.imread(data_dir + \"IMG_4124.jpg\")\n",
    "    # scale image to fit 'window'\n",
    "    img = cv2.resize(img, (0, 0), fx=0.3, fy=0.3)\n",
    "    # Convert to grayscale\n",
    "\n",
    "    WIDTH = img.shape[1]\n",
    "    HEIGHT = img.shape[0]\n",
    "\n",
    "    img_cropped = img[int(HEIGHT / 2 - 200):int(HEIGHT / 2 + 200), int(WIDTH / 2 - 200):int(WIDTH / 2 + 200)]\n",
    "    img_gray_cropped = cv2.cvtColor(img_cropped, cv2.COLOR_BGR2GRAY)\n",
    "    # Apply thresholding\n",
    "    _, img_thresh = cv2.threshold(img_gray_cropped, 250, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Crop center square\n",
    "\n",
    "    mask = img_thresh.copy()\n",
    "    mask = cv2.blur(mask, (5, 5))\n",
    "\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((10, 10), np.uint8))\n",
    "\n",
    "    # INVERT COLOR\n",
    "    mask = cv2.bitwise_not(mask)\n",
    "\n",
    "    reader = easyocr.Reader(lang_list=['pt'], gpu=False)\n",
    "    texto = reader.readtext(mask, detail=0)\n",
    "\n",
    "    texto = texto[0].replace(\" \", \"\")\n",
    "\n",
    "    img_rgb = img_cropped.copy()\n",
    "    cropped_height = img_rgb.shape[0]\n",
    "    cropped_width = img_rgb.shape[1]\n",
    "\n",
    "    cv2.putText(img_rgb, texto, (int(cropped_width / 2), int(cropped_height / 2 + 50)), cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                (255, 0, 0), 2)\n",
    "\n",
    "    return img_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tutuc\\Dropbox\\A - ARTHUR\\5o Semestre\\WebScraping\\projetoWebScraping2023.1\\projeto.ipynb Cell 4\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tutuc/Dropbox/A%20-%20ARTHUR/5o%20Semestre/WebScraping/projetoWebScraping2023.1/projeto.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m img \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(image_dir, filename))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutuc/Dropbox/A%20-%20ARTHUR/5o%20Semestre/WebScraping/projetoWebScraping2023.1/projeto.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Call the digit_recognition function\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tutuc/Dropbox/A%20-%20ARTHUR/5o%20Semestre/WebScraping/projetoWebScraping2023.1/projeto.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m img \u001b[39m=\u001b[39m digit_recognition(img)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutuc/Dropbox/A%20-%20ARTHUR/5o%20Semestre/WebScraping/projetoWebScraping2023.1/projeto.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Display the image using Matplotlib\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutuc/Dropbox/A%20-%20ARTHUR/5o%20Semestre/WebScraping/projetoWebScraping2023.1/projeto.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(img)\n",
      "\u001b[1;32mc:\\Users\\tutuc\\Dropbox\\A - ARTHUR\\5o Semestre\\WebScraping\\projetoWebScraping2023.1\\projeto.ipynb Cell 4\u001b[0m in \u001b[0;36mdigit_recognition\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutuc/Dropbox/A%20-%20ARTHUR/5o%20Semestre/WebScraping/projetoWebScraping2023.1/projeto.ipynb#W2sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m mask \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mbitwise_not(mask)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutuc/Dropbox/A%20-%20ARTHUR/5o%20Semestre/WebScraping/projetoWebScraping2023.1/projeto.ipynb#W2sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m reader \u001b[39m=\u001b[39m easyocr\u001b[39m.\u001b[39mReader(lang_list\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m], gpu\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tutuc/Dropbox/A%20-%20ARTHUR/5o%20Semestre/WebScraping/projetoWebScraping2023.1/projeto.ipynb#W2sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m texto \u001b[39m=\u001b[39m reader\u001b[39m.\u001b[39;49mreadtext(mask, detail\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutuc/Dropbox/A%20-%20ARTHUR/5o%20Semestre/WebScraping/projetoWebScraping2023.1/projeto.ipynb#W2sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m texto \u001b[39m=\u001b[39m texto[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutuc/Dropbox/A%20-%20ARTHUR/5o%20Semestre/WebScraping/projetoWebScraping2023.1/projeto.ipynb#W2sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m img_rgb \u001b[39m=\u001b[39m img_cropped\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\easyocr\\easyocr.py:444\u001b[0m, in \u001b[0;36mReader.readtext\u001b[1;34m(self, image, decoder, beamWidth, batch_size, workers, allowlist, blocklist, detail, rotation_info, paragraph, min_size, contrast_ths, adjust_contrast, filter_ths, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, y_ths, x_ths, add_margin, threshold, bbox_min_score, bbox_min_size, max_candidates, output_format)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[39mParameters:\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[39mimage: file path or numpy-array or a byte stream object\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    442\u001b[0m img, img_cv_grey \u001b[39m=\u001b[39m reformat_input(image)\n\u001b[1;32m--> 444\u001b[0m horizontal_list, free_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdetect(img, \n\u001b[0;32m    445\u001b[0m                                          min_size \u001b[39m=\u001b[39;49m min_size, text_threshold \u001b[39m=\u001b[39;49m text_threshold,\\\n\u001b[0;32m    446\u001b[0m                                          low_text \u001b[39m=\u001b[39;49m low_text, link_threshold \u001b[39m=\u001b[39;49m link_threshold,\\\n\u001b[0;32m    447\u001b[0m                                          canvas_size \u001b[39m=\u001b[39;49m canvas_size, mag_ratio \u001b[39m=\u001b[39;49m mag_ratio,\\\n\u001b[0;32m    448\u001b[0m                                          slope_ths \u001b[39m=\u001b[39;49m slope_ths, ycenter_ths \u001b[39m=\u001b[39;49m ycenter_ths,\\\n\u001b[0;32m    449\u001b[0m                                          height_ths \u001b[39m=\u001b[39;49m height_ths, width_ths\u001b[39m=\u001b[39;49m width_ths,\\\n\u001b[0;32m    450\u001b[0m                                          add_margin \u001b[39m=\u001b[39;49m add_margin, reformat \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m,\\\n\u001b[0;32m    451\u001b[0m                                          threshold \u001b[39m=\u001b[39;49m threshold, bbox_min_score \u001b[39m=\u001b[39;49m bbox_min_score,\\\n\u001b[0;32m    452\u001b[0m                                          bbox_min_size \u001b[39m=\u001b[39;49m bbox_min_size, max_candidates \u001b[39m=\u001b[39;49m max_candidates\n\u001b[0;32m    453\u001b[0m                                          )\n\u001b[0;32m    454\u001b[0m \u001b[39m# get the 1st result from hor & free list as self.detect returns a list of depth 3\u001b[39;00m\n\u001b[0;32m    455\u001b[0m horizontal_list, free_list \u001b[39m=\u001b[39m horizontal_list[\u001b[39m0\u001b[39m], free_list[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\easyocr\\easyocr.py:317\u001b[0m, in \u001b[0;36mReader.detect\u001b[1;34m(self, img, min_size, text_threshold, low_text, link_threshold, canvas_size, mag_ratio, slope_ths, ycenter_ths, height_ths, width_ths, add_margin, reformat, optimal_num_chars, threshold, bbox_min_score, bbox_min_size, max_candidates)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39mif\u001b[39;00m reformat:\n\u001b[0;32m    315\u001b[0m     img, img_cv_grey \u001b[39m=\u001b[39m reformat_input(img)\n\u001b[1;32m--> 317\u001b[0m text_box_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_textbox(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdetector, \n\u001b[0;32m    318\u001b[0m                             img, \n\u001b[0;32m    319\u001b[0m                             canvas_size \u001b[39m=\u001b[39;49m canvas_size, \n\u001b[0;32m    320\u001b[0m                             mag_ratio \u001b[39m=\u001b[39;49m mag_ratio,\n\u001b[0;32m    321\u001b[0m                             text_threshold \u001b[39m=\u001b[39;49m text_threshold, \n\u001b[0;32m    322\u001b[0m                             link_threshold \u001b[39m=\u001b[39;49m link_threshold, \n\u001b[0;32m    323\u001b[0m                             low_text \u001b[39m=\u001b[39;49m low_text,\n\u001b[0;32m    324\u001b[0m                             poly \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m, \n\u001b[0;32m    325\u001b[0m                             device \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice, \n\u001b[0;32m    326\u001b[0m                             optimal_num_chars \u001b[39m=\u001b[39;49m optimal_num_chars,\n\u001b[0;32m    327\u001b[0m                             threshold \u001b[39m=\u001b[39;49m threshold, \n\u001b[0;32m    328\u001b[0m                             bbox_min_score \u001b[39m=\u001b[39;49m bbox_min_score, \n\u001b[0;32m    329\u001b[0m                             bbox_min_size \u001b[39m=\u001b[39;49m bbox_min_size, \n\u001b[0;32m    330\u001b[0m                             max_candidates \u001b[39m=\u001b[39;49m max_candidates,\n\u001b[0;32m    331\u001b[0m                             )\n\u001b[0;32m    333\u001b[0m horizontal_list_agg, free_list_agg \u001b[39m=\u001b[39m [], []\n\u001b[0;32m    334\u001b[0m \u001b[39mfor\u001b[39;00m text_box \u001b[39min\u001b[39;00m text_box_list:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\easyocr\\detection.py:95\u001b[0m, in \u001b[0;36mget_textbox\u001b[1;34m(detector, image, canvas_size, mag_ratio, text_threshold, link_threshold, low_text, poly, device, optimal_num_chars, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m result \u001b[39m=\u001b[39m []\n\u001b[0;32m     94\u001b[0m estimate_num_chars \u001b[39m=\u001b[39m optimal_num_chars \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> 95\u001b[0m bboxes_list, polys_list \u001b[39m=\u001b[39m test_net(canvas_size, mag_ratio, detector,\n\u001b[0;32m     96\u001b[0m                                    image, text_threshold,\n\u001b[0;32m     97\u001b[0m                                    link_threshold, low_text, poly,\n\u001b[0;32m     98\u001b[0m                                    device, estimate_num_chars)\n\u001b[0;32m     99\u001b[0m \u001b[39mif\u001b[39;00m estimate_num_chars:\n\u001b[0;32m    100\u001b[0m     polys_list \u001b[39m=\u001b[39m [[p \u001b[39mfor\u001b[39;00m p, _ \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(polys, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mabs\u001b[39m(optimal_num_chars \u001b[39m-\u001b[39m x[\u001b[39m1\u001b[39m]))]\n\u001b[0;32m    101\u001b[0m                   \u001b[39mfor\u001b[39;00m polys \u001b[39min\u001b[39;00m polys_list]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\easyocr\\detection.py:41\u001b[0m, in \u001b[0;36mtest_net\u001b[1;34m(canvas_size, mag_ratio, net, image, text_threshold, link_threshold, low_text, poly, device, estimate_num_chars)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m# preprocessing\u001b[39;00m\n\u001b[0;32m     39\u001b[0m x \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mtranspose(normalizeMeanVariance(n_img), (\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m     40\u001b[0m      \u001b[39mfor\u001b[39;00m n_img \u001b[39min\u001b[39;00m img_resized_list]\n\u001b[1;32m---> 41\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mfrom_numpy(np\u001b[39m.\u001b[39;49marray(x))\n\u001b[0;32m     42\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     44\u001b[0m \u001b[39m# forward pass\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "# Define the directory where the images are stored\n",
    "image_dir = \"data/img/\"\n",
    "\n",
    "# Loop through all the image files in the directory\n",
    "for filename in os.listdir(image_dir):\n",
    "    \n",
    "    # Load the image\n",
    "    img = cv2.imread(os.path.join(image_dir, filename))\n",
    "    \n",
    "    # Call the digit_recognition function\n",
    "    img = digit_recognition(img)\n",
    "    \n",
    "    # Display the image using Matplotlib\n",
    "    plt.imshow(img)\n",
    "    plt.title(filename)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"data/video/IMG_4123.MOV\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    frame = digit_recognition(frame)\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
